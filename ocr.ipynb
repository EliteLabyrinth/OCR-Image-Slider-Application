{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import os\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "import tesserocr\n",
    "from tesserocr import PyTessBaseAPI, RIL\n",
    "import pytesseract\n",
    "from IPython.display import HTML\n",
    "import easyocr\n",
    "import numpy as np\n",
    "\n",
    "# from paddleocr import PaddleOCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MANGA_IMAGES_DIR = r\"C:\\Workspace\\Learning\\Projects\\Anuvad\\python\\sampleImages\\manga\\shinju_no_necktar\\chapter_0085\"\n",
    "MANHUA_IMAGES_DIR = r\"C:\\Workspace\\Learning\\Projects\\Anuvad\\python\\sampleImages\\manhua\\my_harem_grew_so_large\\chapter_0001\"\n",
    "manga_images = os.listdir(MANGA_IMAGES_DIR)\n",
    "manga_images_sorted = sorted(manga_images)\n",
    "manhua_images = os.listdir(MANHUA_IMAGES_DIR)\n",
    "manhua_images_sorted = sorted(manhua_images)\n",
    "print(\"Manga Images in Sorted Order:\\n\", manga_images_sorted, \"\\n\\n\")\n",
    "print(\"Manhua Images in Sorted Order:\\n\", manhua_images_sorted, \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(img):\n",
    "    img = (\n",
    "        img.convert(\"L\")\n",
    "        .resize([3 * _ for _ in img.size], Image.BICUBIC)\n",
    "        .point(lambda p: p > 75 and p + 100)\n",
    "    )\n",
    "    return img\n",
    "\n",
    "    # # Apply a binary threshold\n",
    "    # threshold = 128\n",
    "    # binary_img = img.point(lambda p: 255 if p > threshold else 0)\n",
    "\n",
    "    # return binary_img\n",
    "\n",
    "    # # Convert to grayscale\n",
    "    # img = img.convert(\"L\")\n",
    "\n",
    "    # # Apply a median filter for noise reduction\n",
    "    # img = img.filter(ImageFilter.MedianFilter(size=3))\n",
    "\n",
    "    # # Enhance contrast\n",
    "    # enhancer = ImageEnhance.Contrast(img)\n",
    "    # img = enhancer.enhance(2)  # Adjust this value as needed\n",
    "\n",
    "    # # Apply binary thresholding\n",
    "    # img = img.point(lambda p: 255 if p > 128 else 0)\n",
    "\n",
    "    # # Convert to numpy array for morphological operations\n",
    "    # img_np = np.array(img)\n",
    "\n",
    "    # # Apply dilation and erosion (morphological operations)\n",
    "    # img_np = ImageOps.invert(\n",
    "    #     Image.fromarray(img_np)\n",
    "    # )  # Invert colors for morphological operations\n",
    "    # img_np = img_np.filter(ImageFilter.MinFilter(3))  # Dilation\n",
    "    # img_np = img_np.filter(ImageFilter.MaxFilter(3))  # Erosion\n",
    "\n",
    "    # # Convert back to binary\n",
    "    # img_np = ImageOps.invert(img_np)\n",
    "    # img_np = img_np.point(lambda p: 255 if p > 128 else 0)\n",
    "\n",
    "    # # Convert back to PIL image\n",
    "    # processed_img = Image.fromarray(np.array(img_np))\n",
    "\n",
    "    # return processed_img\n",
    "\n",
    "\n",
    "def pil_to_cv2(img):\n",
    "    # Convert the PIL image to RGB mode (assuming it's not already)\n",
    "    rgb_image = img.convert(\"RGB\")\n",
    "    # Get the image data as a NumPy array\n",
    "    open_cv_image = np.array(rgb_image)\n",
    "\n",
    "    # Convert color space from RGB (PIL) to BGR (OpenCV)\n",
    "    return cv2.cvtColor(open_cv_image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "\n",
    "def drawImage(img, bboxes=[], scalling_factor=1.0, threashold=70.0):\n",
    "    if img.mode == \"L\":\n",
    "        img = img.convert(\"RGB\")\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    font_path = os.path.join(r\"C:\\Windows\\Fonts\", \"simsun.ttc\")\n",
    "    font = ImageFont.truetype(font_path, size=20)\n",
    "    for box in bboxes:\n",
    "        x1, y1, x2, y2, text, conf = (\n",
    "            box[\"x1\"],\n",
    "            box[\"y1\"],\n",
    "            box[\"x2\"],\n",
    "            box[\"y2\"],\n",
    "            box[\"text\"],\n",
    "            box[\"conf\"],\n",
    "        )\n",
    "        if conf <= threashold:\n",
    "            continue\n",
    "        draw.rectangle(((x1, y1), (x2, y2)), outline=(0, 255, 0), width=2)\n",
    "        draw.text(\n",
    "            (x1, y1 - 10),\n",
    "            text,\n",
    "            font=font,\n",
    "            fill=(255, 0, 0),\n",
    "            stroke_width=0,\n",
    "        )\n",
    "        draw.text(\n",
    "            (x1, y1 - 30),\n",
    "            f\"{conf:.0f}\",\n",
    "            font=font,\n",
    "            fill=(0, 0, 255),\n",
    "            stroke_width=1,\n",
    "        )\n",
    "    display(img.resize(int(scalling_factor * s) for s in img.size))\n",
    "\n",
    "\n",
    "def drawImageFile(image_path, bboxes=[], scalling_factor=1.0, threashold=70.0):\n",
    "    image = Image.open(image_path)\n",
    "\n",
    "    drawImage(image, bboxes, scalling_factor, threashold)\n",
    "\n",
    "\n",
    "def use_tessorocr(image_path, lang=\"eng\", do_preprocess=False):\n",
    "    img = Image.open(image_path)\n",
    "    if do_preprocess:\n",
    "        img = preprocess_image(image_path)\n",
    "\n",
    "    # print(tesserocr.image_to_text(img, lang=lang))\n",
    "    with PyTessBaseAPI(lang=lang) as api:  # type:ignore\n",
    "        api.SetImage(img)\n",
    "\n",
    "        print(api.GetUTF8Text())\n",
    "        print(api.AllWordConfidences())\n",
    "        regions = api.GetRegions()\n",
    "        boxes = api.GetComponentImages(RIL.TEXTLINE, True)\n",
    "        print(\"regions\\n\\n\")\n",
    "        for i in regions:\n",
    "            display(i[0])\n",
    "        print(\"\\n\\nboxes\\n\\n\")\n",
    "        print(boxes, \"\\n\\n\")\n",
    "        for i in boxes:\n",
    "            display(i[0])\n",
    "\n",
    "\n",
    "def use_pytesseract(\n",
    "    image_path,\n",
    "    lang=\"eng\",\n",
    "    config=\"--oem 1 --psm 3\",\n",
    "    scalling_factor=1.0,\n",
    "    threashold=70.0,\n",
    "    do_preprocess=False,\n",
    "):\n",
    "\n",
    "    img = Image.open(image_path)\n",
    "    if do_preprocess:\n",
    "        img = preprocess_image(img)\n",
    "\n",
    "    ocr_text = pytesseract.image_to_string(img, lang=lang, config=config)\n",
    "\n",
    "    print(\"Text Output: \\n\\n------------\\n\", ocr_text, \"\\n\")\n",
    "    data = pytesseract.image_to_data(img, lang=lang, config=config).split(\"\\n\")[1:]\n",
    "    temp_boxes = []\n",
    "    for d in data:\n",
    "        tmp_d = d.split(\"\\t\")\n",
    "        if len(tmp_d) > 1:\n",
    "            temp_boxes.append(\n",
    "                {\n",
    "                    \"level\": int(tmp_d[0]),\n",
    "                    \"page_num\": int(tmp_d[1]),\n",
    "                    \"block_num\": int(tmp_d[2]),\n",
    "                    \"par_num\": int(tmp_d[3]),\n",
    "                    \"line_num\": int(tmp_d[4]),\n",
    "                    \"word_num\": int(tmp_d[5]),\n",
    "                    \"x1\": int(tmp_d[6]),\n",
    "                    \"y1\": int(tmp_d[7]),\n",
    "                    \"x2\": int(tmp_d[6]) + int(tmp_d[8]),\n",
    "                    \"y2\": int(tmp_d[7]) + int(tmp_d[9]),\n",
    "                    \"width\": int(tmp_d[8]),\n",
    "                    \"height\": int(tmp_d[9]),\n",
    "                    \"conf\": float(tmp_d[10]) if tmp_d[10] else 0.0,\n",
    "                    \"text\": tmp_d[11],\n",
    "                }\n",
    "            )\n",
    "    drawImage(img, temp_boxes, scalling_factor, threashold)\n",
    "\n",
    "\n",
    "def use_EasyOCR(\n",
    "    image_path, lang, scalling_factor=1.0, threashold=70.0, do_preprocess=False\n",
    "):\n",
    "    img = Image.open(image_path)\n",
    "    if do_preprocess:\n",
    "        img = preprocess_image(img)\n",
    "    reader = easyocr.Reader([\"en\", lang])\n",
    "    data = reader.readtext(np.array(img) if img.mode == \"L\" else img)\n",
    "    tmp_text = \"\"\n",
    "    tmp_boxes = []\n",
    "    for box in data:\n",
    "        tmp_data = {}\n",
    "        tmp_coords, text, conf = box\n",
    "        if len(tmp_coords) > 3:\n",
    "            x1, y1, x2, y2 = (\n",
    "                tmp_coords[0][0],\n",
    "                tmp_coords[0][1],\n",
    "                tmp_coords[2][0],\n",
    "                tmp_coords[2][1],\n",
    "            )\n",
    "            tmp_data[\"x1\"], tmp_data[\"y1\"], tmp_data[\"x2\"], tmp_data[\"y2\"] = (\n",
    "                x1,\n",
    "                y1,\n",
    "                x2,\n",
    "                y2,\n",
    "            )\n",
    "        tmp_data[\"text\"] = text\n",
    "        tmp_data[\"conf\"] = conf * 100\n",
    "        tmp_boxes.append(tmp_data)\n",
    "        tmp_text += text + \"\\n\"\n",
    "    print(\"\\n Extracted Text:\\n\\n\", tmp_text)\n",
    "    drawImage(\n",
    "        img, bboxes=tmp_boxes, scalling_factor=scalling_factor, threashold=threashold\n",
    "    )\n",
    "\n",
    "\n",
    "# def use_PaddleOCR(\n",
    "#     image_path, lang, scalling_factor=1.0, threashold=70.0, do_preprocess=False\n",
    "# ):\n",
    "#     img = Image.open(image_path)\n",
    "#     if do_preprocess:\n",
    "#         img = preprocess_image(img)\n",
    "#     ocr = PaddleOCR(use_angle_cls=True, lang=\"en\")\n",
    "#     data = ocr.ocr(np.array(img) if img.mode == \"L\" else img)\n",
    "#     print(data)\n",
    "#     return\n",
    "#     tmp_text = \"\"\n",
    "#     tmp_boxes = []\n",
    "#     for box in data:\n",
    "#         tmp_data = {}\n",
    "#         tmp_coords, text, conf = box\n",
    "#         if len(tmp_coords) > 3:\n",
    "#             x1, y1, x2, y2 = (\n",
    "#                 tmp_coords[0][0],\n",
    "#                 tmp_coords[0][1],\n",
    "#                 tmp_coords[2][0],\n",
    "#                 tmp_coords[2][1],\n",
    "#             )\n",
    "#             tmp_data[\"x1\"], tmp_data[\"y1\"], tmp_data[\"x2\"], tmp_data[\"y2\"] = (\n",
    "#                 x1,\n",
    "#                 y1,\n",
    "#                 x2,\n",
    "#                 y2,\n",
    "#             )\n",
    "#         tmp_data[\"text\"] = text\n",
    "#         tmp_data[\"conf\"] = conf * 100\n",
    "#         tmp_boxes.append(tmp_data)\n",
    "#         tmp_text += text + \"\\n\"\n",
    "#     print(\"\\n Extracted Text:\\n\\n\", tmp_text)\n",
    "#     drawImage(\n",
    "#         img, bboxes=tmp_boxes, scalling_factor=scalling_factor, threashold=threashold\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_idx = 6\n",
    "mode = \"manhua\"\n",
    "ocr_tool = \"easyocr\"\n",
    "LANG = \"eng\"\n",
    "if mode == \"manhua\":\n",
    "    if ocr_tool == \"easyocr\":\n",
    "        LANG = \"ch_sim\"\n",
    "    elif ocr_tool == \"tesseract\":\n",
    "        LANG = \"chi_sim\"\n",
    "elif mode == \"manga\":\n",
    "    if ocr_tool == \"easyocr\":\n",
    "        LANG = \"ja\"\n",
    "    elif ocr_tool == \"tesseract\":\n",
    "        LANG = \"jpn\"\n",
    "\n",
    "image_path = (\n",
    "    os.path.join(MANHUA_IMAGES_DIR, manhua_images_sorted[img_idx])\n",
    "    if mode == \"manhua\"\n",
    "    else os.path.join(MANGA_IMAGES_DIR, manga_images_sorted[img_idx])\n",
    ")\n",
    "# use_tessorocr(image_path, lang=\"chi_sim\")\n",
    "# use_pytesseract(image_path, lang=LANG, config=\"--oem 1 --psm 6\", threashold=50.0)\n",
    "use_EasyOCR(\n",
    "    image_path, lang=LANG, threashold=0.0, scalling_factor=1.0, do_preprocess=False\n",
    ")\n",
    "\n",
    "# use_PaddleOCR(\n",
    "#     image_path, lang=LANG, threashold=0.0, scalling_factor=1.0, do_preprocess=False\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "\n",
    "# def prepend_zeros(filename: str, char_to_extract_num: str = \".\") -> str:\n",
    "#     numeric_part, rest = filename.split(char_to_extract_num, 1)\n",
    "#     # Convert the numeric part to an integer\n",
    "#     num = int(numeric_part)\n",
    "\n",
    "#     # Format the numeric part to have exactly 6 digits with leading zeros\n",
    "#     new_numeric_part = f\"{num:06d}\"\n",
    "\n",
    "#     # Construct the new filename\n",
    "#     new_filename = f\"{new_numeric_part}{char_to_extract_num}{rest}\"\n",
    "#     return new_filename\n",
    "\n",
    "\n",
    "# def rename_images_in_folder(folder, char_to_extract_num=\".\"):\n",
    "#     for filename in os.listdir(folder):\n",
    "#         # Check if it's an image file\n",
    "#         if os.path.isfile(os.path.join(folder, filename)) and filename.lower().endswith(\n",
    "#             (\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tiff\")\n",
    "#         ):\n",
    "#             # Generate new filename with sequence number\n",
    "#             new_filename = prepend_zeros(filename, char_to_extract_num)\n",
    "#             source = os.path.join(folder, filename)\n",
    "#             destination = os.path.join(folder, new_filename)\n",
    "#             # Rename the file\n",
    "#             os.rename(source, destination)\n",
    "#             print(f\"{filename}  ->   {new_filename}\")\n",
    "\n",
    "\n",
    "# rename_images_in_folder(\n",
    "#     r\"C:\\Workspace\\Learning\\Projects\\Anuvad\\python\\sampleImages\\manga\\shinju_no_necktar\\chapter_0085\",\n",
    "#     \"-\",\n",
    "# )\n",
    "# rename_images_in_folder(\n",
    "#     r\"C:\\Workspace\\Learning\\Projects\\Anuvad\\python\\sampleImages\\manhua\\my_harem_grew_so_large\\chapter_0001\",\n",
    "#     \".\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import glob\n",
    "# from PIL import Image\n",
    "\n",
    "# image_paths = glob.iglob(\"sampleImages/manhua/*/*/*\", recursive=True)\n",
    "# # for image_path in image_paths:\n",
    "# #     print(image_path)\n",
    "# print(next(image_paths))\n",
    "# img = Image.open(next(image_paths))\n",
    "# print(img.mode)\n",
    "# img = img.convert(\"RGB\")\n",
    "# print(img.mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Merged Boxes:\n",
      " [[[131.0, 40.0], [182.0, 40.0], [182.0, 97.0], [131.0, 97.0]], [[214.0, 77.0], [309.0, 77.0], [309.0, 97.0], [214.0, 97.0]], [[102.0, 276.0], [404.0, 276.0], [404.0, 419.0], [102.0, 419.0]], [[108.0, 428.0], [324.0, 428.0], [324.0, 467.0], [108.0, 467.0]], [[455.0, 1439.0], [763.0, 1439.0], [763.0, 1536.0], [455.0, 1536.0]], [[174.0, 1462.0], [263.0, 1452.0], [286.0, 1647.0], [197.0, 1657.0]], [[458.0, 1536.0], [640.0, 1542.0], [638.0, 1588.0], [457.0, 1582.0]]] \n",
      "\n",
      "Merged Texts:\n",
      " ['免 aoz', 'nh.con', '我，夜孤楼，世 上唯二能修炼纯 阳功之人，慕仙', '门现任门主', '符剑双修，年纪 轻轻就晋入陆地', '-L', '神仙境界']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "boxes = [\n",
    "    [[131.0, 40.0], [178.0, 40.0], [178.0, 61.0], [131.0, 61.0]],\n",
    "    [[131.0, 77.0], [182.0, 77.0], [182.0, 97.0], [131.0, 97.0]],\n",
    "    [[214.0, 77.0], [309.0, 77.0], [309.0, 97.0], [214.0, 97.0]],\n",
    "    [[102.0, 276.0], [404.0, 276.0], [404.0, 320.0], [102.0, 320.0]],\n",
    "    [[110.0, 327.0], [402.0, 327.0], [402.0, 366.0], [110.0, 366.0]],\n",
    "\n",
    "    [[103.0, 369.0], [404.0, 373.0], [404.0, 419.0], [102.0, 415.0]],\n",
    "    [[108.0, 428.0], [324.0, 428.0], [324.0, 467.0], [108.0, 467.0]],\n",
    "\n",
    "    [[455.0, 1439.0], [763.0, 1439.0], [763.0, 1488.0], [455.0, 1488.0]],\n",
    "    [[174.0, 1462.0], [263.0, 1452.0], [286.0, 1647.0], [197.0, 1657.0]],\n",
    "    [[456.0, 1488.0], [761.0, 1492.0], [760.0, 1536.0], [455.0, 1532.0]],\n",
    "    [[458.0, 1536.0], [640.0, 1542.0], [638.0, 1588.0], [457.0, 1582.0]],\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "texts = [\n",
    "\n",
    "    \"免\",\n",
    "    \"aoz\",\n",
    "    \"nh.con\",\n",
    "\n",
    "    \"我，夜孤楼，世\",\n",
    "    \"上唯二能修炼纯\",\n",
    "    \"阳功之人，慕仙\",\n",
    "    \"门现任门主\",\n",
    "    \"符剑双修，年纪\",\n",
    "    \"-L\",\n",
    "    \"轻轻就晋入陆地\",\n",
    "    \"神仙境界\",\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "scores = [\n",
    "    0.9947852492332458,\n",
    "    0.9692819714546204,\n",
    "    0.9721117615699768,\n",
    "    0.9939132928848267,\n",
    "\n",
    "    0.9856699109077454,\n",
    "    0.992316722869873,\n",
    "    0.9826822280883789,\n",
    "\n",
    "    0.9934597015380859,\n",
    "    0.616097092628479,\n",
    "    0.9820842742919922,\n",
    "\n",
    "    0.999176561832428,\n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "def calculate_centroid(box):\n",
    "    x_coords = [point[0] for point in box]\n",
    "    y_coords = [point[1] for point in box]\n",
    "    centroid_x = sum(x_coords) / len(box)\n",
    "    centroid_y = sum(y_coords) / len(box)\n",
    "    return centroid_x, centroid_y\n",
    "\n",
    "\n",
    "def are_boxes_close(box1, box2, threshold):\n",
    "    centroid1 = calculate_centroid(box1)\n",
    "    centroid2 = calculate_centroid(box2)\n",
    "    distance = np.sqrt(\n",
    "        (centroid1[0] - centroid2[0]) ** 2 + (centroid1[1] - centroid2[1]) ** 2\n",
    "    )\n",
    "    return distance < threshold\n",
    "\n",
    "\n",
    "def merge_boxes(boxes, texts, threshold=100):\n",
    "    merged_boxes = []\n",
    "    merged_texts = []\n",
    "    used = [False] * len(boxes)\n",
    "\n",
    "    for i, box in enumerate(boxes):\n",
    "        if used[i]:\n",
    "            continue\n",
    "        current_group = [box]\n",
    "        current_texts = [texts[i]]\n",
    "        used[i] = True\n",
    "        for j in range(i + 1, len(boxes)):\n",
    "            if used[j]:\n",
    "                continue\n",
    "            if are_boxes_close(box, boxes[j], threshold):\n",
    "                current_group.append(boxes[j])\n",
    "                current_texts.append(texts[j])\n",
    "                used[j] = True\n",
    "\n",
    "        if len(current_group) == 1:\n",
    "            merged_boxes.append(current_group[0])\n",
    "            merged_texts.append(current_texts[0])\n",
    "        else:\n",
    "            all_x = [point[0] for b in current_group for point in b]\n",
    "            all_y = [point[1] for b in current_group for point in b]\n",
    "            merged_box = [\n",
    "                [min(all_x), min(all_y)],\n",
    "                [max(all_x), min(all_y)],\n",
    "                [max(all_x), max(all_y)],\n",
    "                [min(all_x), max(all_y)],\n",
    "            ]\n",
    "            merged_boxes.append(merged_box)\n",
    "            merged_texts.append(\" \".join(current_texts))\n",
    "\n",
    "    return merged_boxes, merged_texts\n",
    "\n",
    "\n",
    "merged_boxes, merged_texts = merge_boxes(boxes, texts)\n",
    "print(\"\\n\\nMerged Boxes:\\n\", merged_boxes, \"\\n\\nMerged Texts:\\n\", merged_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn_ml_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
